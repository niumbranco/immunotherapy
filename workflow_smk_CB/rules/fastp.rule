rule trimming_fastp:
    input:
        read_1 = lambda wc: get_input_files(wc)["read_1"],
        read_2 = lambda wc: get_input_files(wc)["read_2"]
    output:
        paired_read_1 = f"{fastp_dir}/{{sample}}_1.clean.fastq.gz",
        paired_read_2 = f"{fastp_dir}/{{sample}}_2.clean.fastq.gz",
        report_json = f"{fastp_dir}/{{sample}}_report.json",
        report_html = f"{fastp_dir}/{{sample}}_report.html",
    params:
        qt = config['fastp']['quality_threshold'],
        ul = config['fastp']['unqualified_limit'],
        lt = config['fastp']['length_threshold'],
        ct = config['fastp']['complexity_threshold'],
    threads: config['fastp']['threads']
    conda: f"{ENV_DIR}/fastp_env.yml"
    shell:
        """
        fastp -w {threads} \
            -i {input.read_1} -I {input.read_2} \
            -o {output.paired_read_1} -O {output.paired_read_2} \
            --correction \
            --qualified_quality_phred {params.qt} \
            --unqualified_percent_limit {params.ul} \
            --length_required {params.lt} \
            --complexity_threshold {params.ct} \
            --json {output.report_json} \
            --html {output.report_html} 

        """

rule fastp_summary:
    input:
        expand("data/fastq/reads_clean/{sample}_report.json", sample=SAMPLES)
    output:
        "data/fastq/reads_clean/fastp_summary_table.csv",
        "data/fastq/reads_clean/fastp_summary_plots.pdf"
    conda:
        f"{ENV_DIR}/r_env.yml"
    script:
        f"{BASEDIR}/scripts/for_snakemake/fastp_summary_smk.R"


